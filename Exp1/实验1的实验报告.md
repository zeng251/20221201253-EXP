# 一、实验目的 

1.了解线性回归模型相关知识。 

    2.学习 scikit-learn 机器学习库的基本使用。 

# 二、实验环境 

系统：windows10 软件：PyCharm 需要安装的库： 

1. Python3.9

2. numpy

3. pandas

4. matplotlib

5. scikit-learn >=0.18

# 三、实验内容 

有如下数据集 Folds5x2_pp.csv，共有 9568 个样本数据，每个数据有 5 列，分别是:AT（温度）, V（压力）, AP（湿度）, RH（压强）, PE（输出电力)。我

们不用纠结于每项具体的意义。 

![](file:///C:\Users\86130\AppData\Local\Temp\ksohtml8964\wps1.png) 

                  图一 样本数据样例 

AT、V、AP、RH 这 4 列作为样本特征，PE 作为样本输出标签，我们试图通过如上数据学习到线性回归模型，也即： 

## _PE_=_θ_0+_θ_1∗_AT_+_θ_2∗_V_+_θ_3∗_AP_+_θ_4∗_RH_

也就是通过线性回归模型求的 _θ_0、_θ_1、_θ_2、_θ_3、_θ_4这 5 个参数。 

    如上样本数据按 3:1 随机划分成训练集和测试集，通过使用 scikit-learn 库中封装好的线性回归算法求出如上参数。 

# 四、实验步骤 

1. 环境搭建 

Win10 系统中安装 python3.9，然后使用 pip 安装所需要的各个库。 

命令如下： 

pip install 库名 

2. 数据预处理 

编写 getTrainSetAndTestSet()函数，对数据集 Folds5x2_pp.csv 进行处

理，按 3:1 的比例划分为训练集和测试集，AT、V、AP、RH 这 4 列作为样本特征，PE 作为样本输出标签。 

def get_train_test_set(data_path):

    """

    加载数据集并划分为训练集和测试集

    :param data_path: CSV文件路径

    :return: 划分后的特征和标签数据集

    """

    try:

        # 读取CSV文件（添加错误处理）

        data = pd.read_csv(data_path)

    except FileNotFoundError:

        raise FileNotFoundError(f"错误：文件路径不存在或文件损坏 - {data_path}")

    # 特征与标签提取（使用英文变量名提升兼容性）

    features = ['AT', 'V', 'AP', 'RH']  # 特征列名

    X = data[features]  # 特征数据（形状：[样本数, 特征数]）

    y = data[['PE']]     # 标签数据（形状：[样本数, 1]）

    # 按3:1比例划分数据集（显式指定test_size=0.25）

    X_train, X_test, y_train, y_test = train_test_split(

        X, y, test_size=0.25, random_state=1  # random_state固定随机种子确保可复现

    )

3. 训练 Linear Regression 模型 

编写 TrainLinearRegression ()函数，首先建立好一个未训练的 LinearRegression()模型，然后，将训练样本传给模型进行训练。 

def train_linear_regression(X_train, y_train):

    """

    训练线性回归模型并输出参数

    :param X_train: 训练集特征

    :param y_train: 训练集标签

    :return: 训练好的模型对象

    """

    # 初始化模型（显式设置是否拟合截距，默认True）

    model = LinearRegression(fit_intercept=True)

    # 模型训练（添加进度提示）

    print("\n开始训练模型...")

    model.fit(X_train, y_train)

    # 提取模型参数

    intercept = model.intercept_[0]  # 截距θ0

    coefficients = model.coef_[0]     # 系数θ1-θ4

    # 格式化输出参数（保留4位小数）

    print(f"截距(θ0)：{intercept:.4f}")

    print(f"系数(θ1-θ4)：{coefficients.round(4)}")

    print("回归方程：")

    equation = "PE = {intercept:.4f}"

    for i, feature in enumerate(features):

        equation += f" + {coefficients[i]:.4f}*{feature}"

    print(equation)

    return model

4．使用测试集评估模型性能分别计算测试集真实值和预测值的均方误差和均方根误差，来评估模型性能。 

def evaluate_model(model, X_test, y_test):

    """

    计算模型在测试集上的评估指标

    :param model: 训练好的模型

    :param X_test: 测试集特征

    :param y_test: 测试集标签

    :return: 预测值数组

    """

    # 预测测试集

    y_pred = model.predict(X_test)

    # 计算均方误差（MSE）和均方根误差（RMSE）

    mse = np.mean((y_test - y_pred) ** 2)

    rmse = np.sqrt(mse)

    # 输出评估结果（使用科学计数法或固定小数）

    print(f"\n均方误差（MSE）：{mse:.4f}")

    print(f"均方根误差（RMSE）：{rmse:.4f}")

    return y_pred
    
    5．可视化利用 matplotlib 库绘制预测值和实际值之前的关系，预测值和实际值越接

近黑色虚线，说明预测值和实际值的误差越小。 

def visualize_predictions(y_test, y_pred):

    """

    绘制预测值与实际值对比图

    :param y_test: 测试集真实值

    :param y_pred: 测试集预测值

    """

    # 设置全局中文字体（解决中文乱码问题）

    plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体

    plt.rcParams['axes.unicode_minus'] = False     # 正确显示负号

    # 创建图表

    fig, ax = plt.subplots(figsize=(10, 6))

    ax.scatter(y_test, y_pred, alpha=0.7, color='blue', label='样本点')  # 添加透明度和标签

    ax.plot(

        [y_test.min(), y_test.max()],  # x轴范围

        [y_test.min(), y_test.max()],  # y轴范围

        'k--', lw=2, label='理想预测线（y=x）'  # 黑色虚线，线宽2

    )

    # 美化图表

    ax.set_xlabel("实际值（PE）", fontsize=12)

    ax.set_ylabel("预测值（PE）", fontsize=12)

    ax.set_title("线性回归预测效果对比", fontsize=14, pad=20)  # pad设置标题间距

    ax.legend()  # 显示图例

    ax.grid(True, linestyle='--', alpha=0.5)  # 浅色网格线

    plt.tight_layout()  # 自动调整布局

    plt.show()
    ![[屏幕截图 2025-05-20 143659.png]]